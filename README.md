# ğŸ¤ Emotion Recognition from Speech  
> ğŸ’¼ Machine Learning Internship Project @ CodeAlpha  

In todayâ€™s fast-paced digital world, where most communication happens virtually, understanding human emotion from speech is a major challenge. Whether itâ€™s online classrooms, customer service calls, or virtual therapy â€” machines often fail to interpret emotions behind voice, which can lead to miscommunication and emotional disconnect.

This project addresses that modern problem by developing an intelligent system that detects emotions like **Happy**, **Fearful**, and **Disgust** using Machine Learning and Speech Processing. By combining the power of **MFCC features**, **Random Forest Classifier**, and a user-friendly **Tkinter GUI**, this tool allows users to record their voice and instantly receive emotion predictions.

---

### ğŸš€ Features  
- ğŸ™ï¸ Real-time speech input recording  
- ğŸ“Š Emotion classification using trained ML model  
- ğŸ§  Uses MFCC feature extraction and Random Forest algorithm  
- ğŸ–¥ï¸ Clean and attractive GUI built with Tkinter  
- âš¡ Fast, lightweight, and easy to use  
- ğŸ“ Organised folder structure for modularity  

---

### ğŸ›  Tech Stack  
- Python 3.10+  
- Scikit-learn  
- Librosa  
- NumPy  
- SoundDevice  
- Tkinter  
- Joblib  

---

### ğŸ“ Project Structure  
Emotion-Recognition-From-Speech/
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ emotion_recognition_model.pkl
â”‚ â””â”€â”€ label_encoder.pkl
â”œâ”€â”€ audio_samples/
â”‚ â””â”€â”€ recorded.wav
â”œâ”€â”€ gui.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

yaml
Copy
Edit

---

### âš™ï¸ How to Run Locally  

1. ğŸ“¥ Clone the repository  

git clone https://github.com/your-username/Emotion-Recognition-From-Speech.git
cd Emotion-Recognition-From-Speech

ğŸ Create and activate conda environment
conda create -n emotion_env python=3.10  
conda activate emotion_env  

ğŸ“¦ Install all dependencies
pip install -r requirements.txt

â–¶ï¸ Run the GUI
python gui.py


Record your voice and let the model predict how you feel!


ğŸ“ Internship Acknowledgement
This project was developed as part of my Machine Learning Internship at CodeAlpha, where I explored practical applications of ML models in speech emotion recognition using real-time user input.

ğŸ¤ Contributions
If youâ€™d like to improve this project (e.g., add more emotion classes, improve accuracy, or support longer audio), feel free to fork, raise an issue, or submit a pull request!

ğŸ”— Connect with Me
ğŸ’¼ LinkedIn: linkedin.com/in/your-profile

ğŸ“¬ Email: your-email@example.com

